{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(32, 32, 3..., activation=\"relu\")`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:46: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:54: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", kernel_regularizer=<keras.reg..., units=100)`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:56: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:58: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", kernel_regularizer=<keras.reg..., units=100)`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:61: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.3)`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "500/500 [==============================] - 58s 115ms/step - loss: 2.1070 - accuracy: 0.3571 - val_loss: 1.6671 - val_accuracy: 0.4859\n",
      "Epoch 2/100\n",
      "  1/500 [..............................] - ETA: 48s - loss: 1.7502 - accuracy: 0.4600"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `test_loss` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 57s 113ms/step - loss: 1.6784 - accuracy: 0.4739 - val_loss: 1.4617 - val_accuracy: 0.5497\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 53s 106ms/step - loss: 1.5010 - accuracy: 0.5299 - val_loss: 1.2984 - val_accuracy: 0.5939\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 55s 109ms/step - loss: 1.3866 - accuracy: 0.5634 - val_loss: 1.2579 - val_accuracy: 0.6080\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 52s 103ms/step - loss: 1.3126 - accuracy: 0.5870 - val_loss: 1.2247 - val_accuracy: 0.6126\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 53s 106ms/step - loss: 1.2671 - accuracy: 0.5997 - val_loss: 1.2662 - val_accuracy: 0.5983\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 57s 115ms/step - loss: 1.2282 - accuracy: 0.6143 - val_loss: 1.1419 - val_accuracy: 0.6350\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 58s 116ms/step - loss: 1.2039 - accuracy: 0.6228 - val_loss: 1.0572 - val_accuracy: 0.6740\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 57s 114ms/step - loss: 1.1785 - accuracy: 0.6321 - val_loss: 1.0892 - val_accuracy: 0.6564\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 1.1663 - accuracy: 0.6335 - val_loss: 1.1188 - val_accuracy: 0.6476\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 57s 115ms/step - loss: 1.1477 - accuracy: 0.6439 - val_loss: 1.1242 - val_accuracy: 0.6489\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 59s 117ms/step - loss: 1.1409 - accuracy: 0.6461 - val_loss: 1.0008 - val_accuracy: 0.6925\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 58s 115ms/step - loss: 1.1250 - accuracy: 0.6536 - val_loss: 1.0580 - val_accuracy: 0.6721\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 59s 119ms/step - loss: 1.1228 - accuracy: 0.6523 - val_loss: 1.0848 - val_accuracy: 0.6672\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 57s 114ms/step - loss: 1.1062 - accuracy: 0.6602 - val_loss: 1.1170 - val_accuracy: 0.6602\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 58s 117ms/step - loss: 1.1026 - accuracy: 0.6608 - val_loss: 0.9815 - val_accuracy: 0.6998\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 1.0974 - accuracy: 0.6632 - val_loss: 1.0344 - val_accuracy: 0.6813\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 1.0865 - accuracy: 0.6666 - val_loss: 1.0504 - val_accuracy: 0.6787\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 63s 127ms/step - loss: 1.0839 - accuracy: 0.6699 - val_loss: 1.1206 - val_accuracy: 0.6557\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 60s 119ms/step - loss: 1.0796 - accuracy: 0.6698 - val_loss: 1.0599 - val_accuracy: 0.6831\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 56s 113ms/step - loss: 1.0745 - accuracy: 0.6701 - val_loss: 0.9866 - val_accuracy: 0.6925\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.0623 - accuracy: 0.6749 - val_loss: 1.0657 - val_accuracy: 0.6807\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 58s 116ms/step - loss: 1.0611 - accuracy: 0.6762 - val_loss: 1.0040 - val_accuracy: 0.6967\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 55s 109ms/step - loss: 1.0497 - accuracy: 0.6799 - val_loss: 0.9679 - val_accuracy: 0.7090\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 53s 105ms/step - loss: 1.0530 - accuracy: 0.6783 - val_loss: 1.0385 - val_accuracy: 0.6888\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 1.0496 - accuracy: 0.6824 - val_loss: 0.9587 - val_accuracy: 0.7086\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 70s 139ms/step - loss: 1.0372 - accuracy: 0.6844 - val_loss: 1.0185 - val_accuracy: 0.6916\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 56s 113ms/step - loss: 1.0431 - accuracy: 0.6825 - val_loss: 0.9769 - val_accuracy: 0.7033\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 53s 106ms/step - loss: 1.0454 - accuracy: 0.6825 - val_loss: 0.9630 - val_accuracy: 0.7093\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 52s 104ms/step - loss: 1.0321 - accuracy: 0.6854 - val_loss: 0.9900 - val_accuracy: 0.7025\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 52s 104ms/step - loss: 1.0375 - accuracy: 0.6850 - val_loss: 1.0285 - val_accuracy: 0.6858\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 52s 103ms/step - loss: 1.0250 - accuracy: 0.6894 - val_loss: 0.9520 - val_accuracy: 0.7132\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 52s 105ms/step - loss: 1.0288 - accuracy: 0.6902 - val_loss: 0.9888 - val_accuracy: 0.6984\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 53s 106ms/step - loss: 1.0320 - accuracy: 0.6876 - val_loss: 1.1402 - val_accuracy: 0.6586\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 53s 107ms/step - loss: 1.0216 - accuracy: 0.6905 - val_loss: 1.0063 - val_accuracy: 0.6994\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 52s 104ms/step - loss: 1.0166 - accuracy: 0.6919 - val_loss: 0.9878 - val_accuracy: 0.7029\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 54s 107ms/step - loss: 1.0176 - accuracy: 0.6922 - val_loss: 0.9833 - val_accuracy: 0.7077\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 53s 106ms/step - loss: 1.0189 - accuracy: 0.6907 - val_loss: 0.9824 - val_accuracy: 0.7027\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 53s 107ms/step - loss: 1.0160 - accuracy: 0.6946 - val_loss: 1.0380 - val_accuracy: 0.6899\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 52s 104ms/step - loss: 1.0121 - accuracy: 0.6956 - val_loss: 0.9374 - val_accuracy: 0.7178\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 53s 106ms/step - loss: 1.0071 - accuracy: 0.6962 - val_loss: 0.9188 - val_accuracy: 0.7245\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 55s 110ms/step - loss: 1.0045 - accuracy: 0.6980 - val_loss: 0.9642 - val_accuracy: 0.7125\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 60s 119ms/step - loss: 1.0060 - accuracy: 0.6966 - val_loss: 0.9739 - val_accuracy: 0.7043\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 65s 130ms/step - loss: 1.0104 - accuracy: 0.6954 - val_loss: 1.0555 - val_accuracy: 0.6881\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 0.9952 - accuracy: 0.6996 - val_loss: 0.9656 - val_accuracy: 0.7119\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 1.0030 - accuracy: 0.6977 - val_loss: 0.9317 - val_accuracy: 0.7227\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 63s 125ms/step - loss: 1.0008 - accuracy: 0.6980 - val_loss: 0.9497 - val_accuracy: 0.7146\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 56s 113ms/step - loss: 1.0007 - accuracy: 0.6996 - val_loss: 0.9846 - val_accuracy: 0.7059\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 55s 110ms/step - loss: 0.9890 - accuracy: 0.7002 - val_loss: 0.9377 - val_accuracy: 0.7214\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 52s 104ms/step - loss: 0.9936 - accuracy: 0.7026 - val_loss: 0.8903 - val_accuracy: 0.7344\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 51s 102ms/step - loss: 0.9980 - accuracy: 0.7006 - val_loss: 0.9469 - val_accuracy: 0.7211\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 53s 107ms/step - loss: 0.9936 - accuracy: 0.7029 - val_loss: 1.0448 - val_accuracy: 0.6945\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 55s 109ms/step - loss: 0.9845 - accuracy: 0.7068 - val_loss: 0.9606 - val_accuracy: 0.7146\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 55s 109ms/step - loss: 0.9885 - accuracy: 0.7010 - val_loss: 0.9401 - val_accuracy: 0.7187\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 55s 109ms/step - loss: 0.9946 - accuracy: 0.7001 - val_loss: 0.9166 - val_accuracy: 0.7234\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 53s 106ms/step - loss: 0.9835 - accuracy: 0.7040 - val_loss: 1.0152 - val_accuracy: 0.6980\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 56s 112ms/step - loss: 0.9839 - accuracy: 0.7040 - val_loss: 0.9283 - val_accuracy: 0.7228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "500/500 [==============================] - 51s 102ms/step - loss: 0.9863 - accuracy: 0.7044 - val_loss: 0.9480 - val_accuracy: 0.7170\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 51s 102ms/step - loss: 0.9857 - accuracy: 0.7039 - val_loss: 0.9516 - val_accuracy: 0.7147\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 50s 101ms/step - loss: 0.9769 - accuracy: 0.7080 - val_loss: 1.0281 - val_accuracy: 0.6936\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 0.9790 - accuracy: 0.7068 - val_loss: 0.9865 - val_accuracy: 0.7096\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 68s 136ms/step - loss: 0.9845 - accuracy: 0.7055 - val_loss: 0.9802 - val_accuracy: 0.7125\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 67s 134ms/step - loss: 0.9804 - accuracy: 0.7035 - val_loss: 1.0021 - val_accuracy: 0.7014\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 69s 138ms/step - loss: 0.9768 - accuracy: 0.7067 - val_loss: 1.0156 - val_accuracy: 0.6991\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 69s 138ms/step - loss: 0.9789 - accuracy: 0.7060 - val_loss: 0.9888 - val_accuracy: 0.7056\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 68s 137ms/step - loss: 0.9768 - accuracy: 0.7073 - val_loss: 0.9699 - val_accuracy: 0.7119\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 68s 137ms/step - loss: 0.9765 - accuracy: 0.7082 - val_loss: 1.0278 - val_accuracy: 0.6946\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 68s 136ms/step - loss: 0.9764 - accuracy: 0.7054 - val_loss: 0.9642 - val_accuracy: 0.7102\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 67s 133ms/step - loss: 0.9817 - accuracy: 0.7085 - val_loss: 0.9710 - val_accuracy: 0.7102\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 69s 137ms/step - loss: 0.9724 - accuracy: 0.7089 - val_loss: 1.0414 - val_accuracy: 0.6924\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 68s 137ms/step - loss: 0.9714 - accuracy: 0.7093 - val_loss: 0.9010 - val_accuracy: 0.7318\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 68s 136ms/step - loss: 0.9727 - accuracy: 0.7102 - val_loss: 0.9226 - val_accuracy: 0.7230\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 66s 131ms/step - loss: 0.9686 - accuracy: 0.7085 - val_loss: 1.0890 - val_accuracy: 0.6839\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 67s 134ms/step - loss: 0.9738 - accuracy: 0.7107 - val_loss: 0.9633 - val_accuracy: 0.7157\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 67s 134ms/step - loss: 0.9656 - accuracy: 0.7121 - val_loss: 0.9231 - val_accuracy: 0.7272\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 68s 137ms/step - loss: 0.9668 - accuracy: 0.7105 - val_loss: 0.8929 - val_accuracy: 0.7341\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 67s 135ms/step - loss: 0.9630 - accuracy: 0.7122 - val_loss: 0.9280 - val_accuracy: 0.7241\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 66s 132ms/step - loss: 0.9688 - accuracy: 0.7118 - val_loss: 1.0403 - val_accuracy: 0.6943\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 68s 136ms/step - loss: 0.9636 - accuracy: 0.7133 - val_loss: 0.9212 - val_accuracy: 0.7278\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 67s 135ms/step - loss: 0.9634 - accuracy: 0.7108 - val_loss: 0.9157 - val_accuracy: 0.7240\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 67s 135ms/step - loss: 0.9633 - accuracy: 0.7104 - val_loss: 0.8697 - val_accuracy: 0.7405\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 66s 132ms/step - loss: 0.9621 - accuracy: 0.7118 - val_loss: 0.9338 - val_accuracy: 0.7201\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 66s 132ms/step - loss: 0.9583 - accuracy: 0.7147 - val_loss: 0.9191 - val_accuracy: 0.7225\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 65s 130ms/step - loss: 0.9616 - accuracy: 0.7140 - val_loss: 0.8877 - val_accuracy: 0.7337\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 67s 134ms/step - loss: 0.9572 - accuracy: 0.7157 - val_loss: 0.8955 - val_accuracy: 0.7340\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 69s 138ms/step - loss: 0.9608 - accuracy: 0.7141 - val_loss: 0.9084 - val_accuracy: 0.7323\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 66s 132ms/step - loss: 0.9562 - accuracy: 0.7149 - val_loss: 0.9495 - val_accuracy: 0.7188\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 68s 136ms/step - loss: 0.9591 - accuracy: 0.7148 - val_loss: 0.9817 - val_accuracy: 0.7108\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 67s 133ms/step - loss: 0.9654 - accuracy: 0.7126 - val_loss: 1.0233 - val_accuracy: 0.6995\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 66s 132ms/step - loss: 0.9572 - accuracy: 0.7142 - val_loss: 0.8933 - val_accuracy: 0.7336\n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 64s 129ms/step - loss: 0.9632 - accuracy: 0.7129 - val_loss: 0.9576 - val_accuracy: 0.7161\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 65s 130ms/step - loss: 0.9568 - accuracy: 0.7150 - val_loss: 0.8592 - val_accuracy: 0.7488\n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 66s 133ms/step - loss: 0.9575 - accuracy: 0.7153 - val_loss: 0.8726 - val_accuracy: 0.7388\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 67s 134ms/step - loss: 0.9541 - accuracy: 0.7171 - val_loss: 0.9118 - val_accuracy: 0.7271\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 67s 135ms/step - loss: 0.9583 - accuracy: 0.7134 - val_loss: 0.9821 - val_accuracy: 0.7148\n",
      "Epoch 96/100\n",
      "500/500 [==============================] - 66s 132ms/step - loss: 0.9538 - accuracy: 0.7139 - val_loss: 0.9775 - val_accuracy: 0.7110\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 67s 135ms/step - loss: 0.9568 - accuracy: 0.7138 - val_loss: 0.9698 - val_accuracy: 0.7130\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 68s 136ms/step - loss: 0.9518 - accuracy: 0.7156 - val_loss: 0.9136 - val_accuracy: 0.7309\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 66s 132ms/step - loss: 0.9572 - accuracy: 0.7151 - val_loss: 1.0086 - val_accuracy: 0.7012\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 67s 134ms/step - loss: 0.9567 - accuracy: 0.7142 - val_loss: 0.8907 - val_accuracy: 0.7361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a585cf0dc8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7)\n",
    "        return X_train, X_test\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test = normalize(x_train, x_test) \n",
    "\n",
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "one_hot=OneHotEncoder()\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()\n",
    "\n",
    "\n",
    "classifier=Sequential()\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32,3,3,input_shape=(32,32,3),activation='relu'))\n",
    "classifier.add(BatchNormalization())##BatchNormalization\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32,3,3,activation='relu'))\n",
    "classifier.add(BatchNormalization())##BatchNormalization\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "classifier.add(Dense(output_dim=100,activation='relu',kernel_regularizer=regularizers.l2(l=0.001))) ##regularizers\n",
    "classifier.add(BatchNormalization()) ##BatchNormalization\n",
    "classifier.add(Dropout(p=0.5)) ##Dropout\n",
    "\n",
    "classifier.add(Dense(output_dim=100,activation='relu',kernel_regularizer=regularizers.l2(0.001)))##regularizers\n",
    "classifier.add(BatchNormalization()) ##BatchNormalization\n",
    "\n",
    "classifier.add(Dropout(p=0.3))##Dropout\n",
    "\n",
    "classifier.add(Dense(output_dim=10,activation='softmax'))\n",
    "#超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator ##Augmentation\n",
    "img_gen = ImageDataGenerator( featurewise_center=True,featurewise_std_normalization=True,rotation_range=10,width_shift_range=0.1,\n",
    "                                            height_shift_range=0.1,shear_range=0.1,zoom_range=0.1,horizontal_flip=True,vertical_flip=False,dtype=np.float32)\n",
    "img_gen.fit(x_train)\n",
    "\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(monitor='test_loss', patience=8, verbose=1) ##earlystop\n",
    "\n",
    "##開始訓練\n",
    "classifier.fit_generator(img_gen.flow(x_train, y_train, batch_size=100) ,steps_per_epoch=500,\n",
    "                               epochs=100, validation_data = (x_test, y_test),callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 上方有用到一些避免Overfitting 的方法，有興趣的學員們可以參考這篇Medium:https://medium.com/@CinnamonAITaiwan/cnn%E5%85%A5%E9%96%80-overfitting-d10acd15ec21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22515756, 0.00089316, 0.51734537, 0.06329948, 0.04702778,\n",
       "        0.05431223, 0.03394958, 0.0027196 , 0.05092879, 0.00436651]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7) \n",
    "        return X_train, X_test,mean,std\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test,mean_train,std_train = normalize(x_train, x_test) \n",
    "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
    "classifier.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
